{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, platform\n",
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "mne.__version__\n",
    "from mne.viz import plot_alignment, snapshot_brain_montage\n",
    "import shutil\n",
    "from mne.datasets import eegbci\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from mne_bids import write_raw_bids, BIDSPath, print_dir_tree, make_dataset_description\n",
    "# from mne_bids.stats import count_events\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' VARIABLES '''\n",
    "\n",
    "dataset = 'eeg'\n",
    "\n",
    "amount_of_subjects = 27 # Change the range so the process is faster\n",
    "\n",
    "numC = 8\n",
    "\n",
    "angles = [i * 180./numC for i in range(numC)]\n",
    "\n",
    "x_labels = np.array(angles)\n",
    "\n",
    "resample = True # speeds up the procees but showing slighly worse results\n",
    "resample_frequency = 50 # in Hz, original freq is 500Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency before: 500.0\n",
      "Frequency after: 50.0\n",
      "Frequency before: 500.0\n",
      "Frequency after: 50.0\n",
      "Frequency before: 500.0\n",
      "Frequency after: 50.0\n",
      "Frequency before: 500.0\n",
      "Frequency after: 50.0\n",
      "Frequency before: 500.0\n",
      "Frequency after: 50.0\n",
      "Frequency before: 500.0\n",
      "Frequency after: 50.0\n",
      "Frequency before: 500.0\n",
      "Frequency after: 50.0\n",
      "Frequency before: 500.0\n",
      "Frequency after: 50.0\n",
      "Frequency before: 500.0\n",
      "Frequency after: 50.0\n",
      "Frequency before: 500.0\n",
      "Frequency after: 50.0\n",
      "Frequency before: 500.0\n",
      "Frequency after: 50.0\n",
      "Frequency before: 500.0\n",
      "Frequency after: 50.0\n",
      "Frequency before: 500.0\n",
      "Frequency after: 50.0\n",
      "Frequency before: 500.0\n",
      "Frequency after: 50.0\n",
      "Frequency before: 500.0\n",
      "Frequency after: 50.0\n",
      "Frequency before: 500.0\n",
      "Frequency after: 50.0\n",
      "Frequency before: 500.0\n",
      "Frequency after: 50.0\n",
      "Frequency before: 500.0\n",
      "Frequency after: 50.0\n",
      "Frequency before: 500.0\n",
      "Frequency after: 50.0\n",
      "Frequency before: 500.0\n",
      "Frequency after: 50.0\n",
      "Frequency before: 500.0\n",
      "Frequency after: 50.0\n",
      "Frequency before: 500.0\n",
      "Frequency after: 50.0\n",
      "Frequency before: 500.0\n",
      "Frequency after: 50.0\n",
      "Frequency before: 500.0\n",
      "Frequency after: 50.0\n",
      "Frequency before: 500.0\n",
      "Frequency after: 50.0\n",
      "Frequency before: 500.0\n",
      "Frequency after: 50.0\n"
     ]
    }
   ],
   "source": [
    "from toolbox.methods import read_data\n",
    "all_epochs, all_rawdata = read_data (task = 'main', resample=resample, amount_of_subjects=amount_of_subjects, resample_frequency=resample_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "# from pyrcn.echo_state_network import ESNClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from catboost import CatBoostClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def train_timepoints(X, y, verbose=False, display_roc=False, acc_only = False):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    minority = np.unique(y_train,return_counts=True)[1][0]\n",
    "    mayority = np.unique(y_train,return_counts=True)[1][1]\n",
    "    # print(mayority/minority)\n",
    "    class_weight = {\n",
    "        0: 1.0,  \n",
    "        1: mayority/minority\n",
    "    }\n",
    "    sample_weights = np.array([class_weight[label] for label in y_train])\n",
    "    \n",
    "    # clf = CatBoostClassifier(task_type = 'GPU')\n",
    "    clf = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "    clf = RandomForestClassifier(n_jobs=-1)\n",
    "    # clf = LinearSVC(random_state=0, loss=\"hinge\") # Faster than Random Forest\n",
    "    clf.fit(X_train, y_train,\n",
    "            sample_weight=sample_weights\n",
    "            )\n",
    "\n",
    "    y_pred = clf.predict(X_test)    \n",
    "    if verbose:\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print(np.unique(y_test, return_counts=True))\n",
    "        print(np.unique(y_pred, return_counts=True))\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc = roc_auc_score(y_test, y_pred)\n",
    "    # features = clf.feature_importances_\n",
    "    if display_roc:\n",
    "        # I think this is not working\n",
    "        from sklearn.metrics import roc_curve\n",
    "        from sklearn.metrics import RocCurveDisplay\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred, pos_label=clf.classes_[1])\n",
    "        roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()\n",
    "        return roc_display\n",
    "    # if np.unique(y_pred, return_counts=True)[1].shape[0] == 1:\n",
    "    #     unique_pred_0 = 0\n",
    "    #     unique_pred_1 = np.unique(y_pred, return_counts=True)[1][0]  \n",
    "    # else:\n",
    "    #     unique_pred_0 = np.unique(y_pred, return_counts=True)[1][0]\n",
    "    #     unique_pred_1 = np.unique(y_pred, return_counts=True)[1][1]\n",
    "    if acc_only:\n",
    "        return accuracy\n",
    "    return accuracy, f1, roc #, features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "real data mean acc = 0.64\n",
    "\n",
    "shuffled data mean acc = 0.58\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean acc for all subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on subj:  0\n",
      "Working on subj:  1\n",
      "Working on subj:  2\n",
      "Working on subj:  3\n",
      "Working on subj:  4\n",
      "Working on subj:  5\n",
      "Working on subj:  6\n",
      "Working on subj:  7\n",
      "Working on subj:  8\n",
      "Working on subj:  9\n",
      "Working on subj:  10\n",
      "Working on subj:  11\n",
      "Working on subj:  12\n",
      "Working on subj:  13\n",
      "Working on subj:  14\n",
      "Working on subj:  15\n",
      "Working on subj:  16\n",
      "Working on subj:  17\n",
      "Working on subj:  18\n",
      "Working on subj:  19\n",
      "Working on subj:  20\n",
      "Working on subj:  21\n",
      "Working on subj:  22\n",
      "Working on subj:  23\n",
      "Working on subj:  24\n",
      "Working on subj:  25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x2/l6kq7w2s48bbjcgczm1ll_fm0000gn/T/ipykernel_64458/3318715416.py:24: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  numpy_timepoint_accuracy = np.array(timepoint_accuracy)\n"
     ]
    }
   ],
   "source": [
    "'''30s per subject, 13min for 26 subjects '''\n",
    "\n",
    "import random\n",
    "subject_acc = [None]*amount_of_subjects\n",
    "timepoint_accuracy = [None]*amount_of_subjects\n",
    "\n",
    "bool_shuffled = False\n",
    "\n",
    "for subj in range(amount_of_subjects-1):\n",
    "    \n",
    "    print('Working on subj: ', subj)\n",
    "    X = all_rawdata[subj]['epoch_dat']\n",
    "    y = np.where(all_rawdata[subj]['metadata']['r_map'] == 45, 1, 0)\n",
    "    y2 = all_rawdata[subj]['metadata']['deci']\n",
    "    y3 = [a ^ b for a, b in zip(y, y2)]\n",
    "    if bool_shuffled: random.shuffle(y3)\n",
    "    numT = X.shape[2]\n",
    "    timepoint_accuracy[subj] = [None]*numT\n",
    "    for timepoint in range(numT):\n",
    "        # print(timepoint)\n",
    "        X_training = X[:,:,timepoint]\n",
    "        timepoint_accuracy[subj][timepoint] = train_timepoints(X_training, y3, verbose=False, acc_only=True)\n",
    "\n",
    "numpy_timepoint_accuracy = np.array(timepoint_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
